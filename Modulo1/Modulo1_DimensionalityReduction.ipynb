{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3011cebd",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b3772",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from sklearn import tree\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c59f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train.txt\", header=None,  delim_whitespace=True)\n",
    "y_train = pd.read_csv(\"y_train.txt\", header=None, delim_whitespace=True )\n",
    "X_test = pd.read_csv(\"X_test.txt\", header=None, delim_whitespace=True )\n",
    "y_test = pd.read_csv(\"y_test.txt\", header=None, delim_whitespace=True )\n",
    "features = pd.read_csv(\"features.txt\", header=None, delim_whitespace=True )\n",
    "subject = pd.read_csv(\"subject_train.txt\", header=None, delim_whitespace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8ca698",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = features\n",
    "subjects = subject\n",
    "feature.drop(0,inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f28e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inseriamo l'intestazione al dataset\n",
    "lista=[]\n",
    "feat_transpa = feature.transpose()\n",
    "for i in range(561):\n",
    "    lista.append(feat_transpa.iloc[0][i])\n",
    "X_test.columns=lista    \n",
    "X_train.columns=lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb64748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminiamo le colonne che contengono la stima mad in quanto quasi uguale a dev.std\n",
    "stringa=\"mad()\"\n",
    "for col in X_train.columns:\n",
    "    if(stringa in col):\n",
    "        X_train.drop(labels=col, axis=1, inplace=True)\n",
    "for col in X_test.columns:\n",
    "    if(stringa in col):\n",
    "        X_test.drop(labels=col, axis=1, inplace=True)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535af21f",
   "metadata": {},
   "source": [
    "## Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ae3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f503fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the variance and name of variables\n",
    "variance = X_train.var()\n",
    "columns = X_train.columns\n",
    "variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5697c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=np.arange(0,len(columns))\n",
    "df=pd.DataFrame({'Columns': index, 'Variance': variance})\n",
    "df1= df.sort_values(by='Variance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbed1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the names of variables having variance more than a threshold value\n",
    "variable = [ ]\n",
    "for i in range(0, len(variance)):\n",
    "    if variance[i]>=0.29: #setting the threshold as 1%\n",
    "        variable.append(columns[i])\n",
    "len(variable)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ea14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Variance vs Columns\n",
    "sns.set(rc = {'figure.figsize':(7,5)})\n",
    "p=sns.lineplot(data=df1, x=index,  y=\"Variance\")\n",
    "p.set_xlabel(\"N° cols\", fontsize = 15)\n",
    "p.set_ylabel(\"Variance\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3122965",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=(0.29)) # Valore ideale come trad-off tra accuracy e n°colonne\n",
    "X_train_sel= sel.fit_transform(X_train)\n",
    "X_train_sel.shape #vediamo che sputa fuori 97 colonne\n",
    "ciao = pd.DataFrame(X_train_sel)\n",
    "#len(X_train_sel[0][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b55a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sel = sel.transform(X_test)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train_sel, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_sel)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66121629",
   "metadata": {},
   "source": [
    "###  Accuracy vs Var_Thresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579d241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=np.arange(0.01, 0.4, 0.01)\n",
    "acc=[]\n",
    "\n",
    "for i in ind:\n",
    "    sel = VarianceThreshold(threshold=(i))\n",
    "    X_train_sel = sel.fit_transform(X_train)\n",
    "    X_test_sel = sel.transform(X_test)\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train_sel, y_train)\n",
    "    y_pred = clf.predict(X_test_sel)\n",
    "    acc.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "#plot\n",
    "sns.set(rc = {'figure.figsize':(11,7)})\n",
    "p=sns.lineplot( x=ind,  y=acc)\n",
    "p.set_xlabel(\"Var_Threshold\", fontsize = 15)\n",
    "p.set_ylabel(\"Accuracy\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dce6096",
   "metadata": {},
   "source": [
    "## Univariate Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f51b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410deadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SelectKBest(score_func=f_classif, k=30) # scegliamo il numero di feature che desideriamo secondo lo score f_classif di ANOVA\n",
    "X_train_sel = sel.fit_transform(X_train, np.ravel(y_train))\n",
    "\n",
    "X_train_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239545bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sel = sel.transform(X_test)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train_sel, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_sel)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf51bae1",
   "metadata": {},
   "source": [
    "### Uivariate FS with ANOVA vs N°cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c439603",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1=np.arange(10,100,1)\n",
    "acc1=[]\n",
    "for i in ind1:\n",
    "    sel = SelectKBest(score_func=f_classif, k=i) \n",
    "    X_train_sel = sel.fit_transform(X_train, np.ravel(y_train))\n",
    "    X_test_sel = sel.transform(X_test)\n",
    "    clf1 = DecisionTreeClassifier(random_state=42)\n",
    "    clf1.fit(X_train_sel, y_train)\n",
    "    y_pred = clf1.predict(X_test_sel)\n",
    "    acc1.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "sns.set(rc = {'figure.figsize':(11,7)})\n",
    "p=sns.lineplot( x=ind1,  y=acc1)\n",
    "p.set_xlabel(\"K_features\", fontsize = 15)\n",
    "p.set_ylabel(\"Accuracy\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ef19ac",
   "metadata": {},
   "source": [
    "## RFE SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9ebebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7ae5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SelectFromModel(DecisionTreeClassifier(max_depth=None, min_samples_split=30, min_samples_leaf=30, random_state=42)) #qui selezioniamo l'algoritmo da utilizzare\n",
    "X_train_sel = sel.fit_transform(X_train, y_train)\n",
    "X_train_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69ce8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nome colonne salvate\n",
    "features_idx = sel.get_support()\n",
    "features_name = X_train.columns[features_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a360ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X con risultati migliori!\n",
    "X_train_new = X_train[features_name]\n",
    "X_test_new = X_test[features_name] \n",
    "X_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e8c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sel = sel.transform(X_test)\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=30, min_samples_leaf=30, random_state=42)\n",
    "clf.fit(X_train_sel, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_sel)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a01b07",
   "metadata": {},
   "source": [
    "### Alternativa con randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67707875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b26af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SelectFromModel(RandomForestClassifier(), max_features=32)\n",
    "X_train_sel = sel.fit_transform(X_train, np.ravel(y_train))\n",
    "X_train_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef880d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.get_support() #To see which features are important \n",
    "select_feat= X_train.columns[(sel.get_support())] \n",
    "#select_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a5446",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sel = sel.transform(X_test)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_sel, np.ravel(y_train))\n",
    "\n",
    "y_pred = clf.predict(X_test_sel)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e62f0",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a72f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdbe445",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(estimator=clf, step=1)\n",
    "rfe = rfe.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fcbd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rfe_features = pd.DataFrame({'Feature': list(X_train.columns),\n",
    "                                      'Ranking': rfe.ranking_})\n",
    "selected_rfe_features.sort_values(by='Ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc261914",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.where(selected_rfe_features.iloc[:,1]==1) # salvo in a le feature più importanti\n",
    "np.count_nonzero(a) #conto quante sono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc80b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe = rfe.transform(X_train)\n",
    "X_test_rfe = rfe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30781760",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model = clf.fit(X_train_rfe, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f3546",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_model.predict(X_test_rfe)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680f018",
   "metadata": {},
   "source": [
    "###  RFE with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82448dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv = RFECV(estimator=clf_dt, step=1, cv=5, scoring='accuracy')\n",
    "rfecv = rfecv.fit(X_train, y_train)\n",
    "print('optimal number of features:', rfecv.n_features_)\n",
    "print('Best features:', X_train.columns[rfecv.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8decc51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = X_train.columns[rfecv.support_]\n",
    "X_train_new = X_train[var]\n",
    "X_test_new = X_test[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbbaf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt1 = dt.fit(X_train_new, y_train)\n",
    "y_pred = dt1.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7a36b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833af2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfecv.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4038ed4",
   "metadata": {},
   "source": [
    "## PCA (Principal Component Analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f153d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2f383",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=26)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebd00bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = len(pca.explained_variance_ratio_)\n",
    "indx = np.arange(num_components)\n",
    "values = pca.explained_variance_ratio_\n",
    "cumulative = np.cumsum(values) # in questo vettore salviamo la varianza cumulata\n",
    "cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d3833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#questo comando ci indica i valori in stringa del vettore! *100 serve per trasformare il valore in percetuale, mentre il secondo argomento indica quantecifre decimale ci vogliono\n",
    "r\"%s\" % ((str(values[4] *100 ) [:3])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7818f570",
   "metadata": {},
   "source": [
    "### Variance explained ratio for each Principal Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d2b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT Variance Explained Ratio for each prinicpal components\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "ax=plt.subplot(111) #pos sarebbe il primo parametro ed è composto da 3 digit, il primo per indicare il numero di righe, il secondo le colonne e il terzo l'indice del subplot\n",
    "\n",
    "\n",
    "ax.bar(indx, values)\n",
    "ax.plot(indx, cumulative)\n",
    "\n",
    "#add annotation of percentage of each component to graph \n",
    "for val in range(num_components):\n",
    "    ax.annotate(r\"%s\" % ((str(values[val] * 100) [:3])), (indx[val], values[val]),\n",
    "               va= \"bottom\", ha= \"center\", fontsize= 12)\n",
    "    \n",
    "#setting tick parameters    \n",
    "ax.xaxis.set_tick_params(width=1)\n",
    "ax.yaxis.set_tick_params(width=3, length=15)\n",
    "ax.set_xlabel(\"Principal Component Values\", size=13)\n",
    "ax.set_ylabel(\"Variance Explained Percentage\", size=13)\n",
    "plt.title(\"Variance Explained Ratio for each prinicpal components\", size=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "clf = DecisionTreeClassifier(min_samples_leaf=3, random_state=42)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbeb688",
   "metadata": {},
   "source": [
    "### Cumulative_explained_variance / PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de9afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components',fontsize = 15, fontweight = 'bold')\n",
    "plt.ylabel('cumulative explained variance',fontsize = 15, fontweight = 'bold')\n",
    "#plt.xscale(\"symlog\")\n",
    "#plt.xlim(0,200,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd8b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, cmap=plt.cm.prism, edgecolor='k', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d1bd3e",
   "metadata": {},
   "source": [
    "## Visualizzazione PCA 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e680b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aaef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(data = X_train_pca, columns = ['pca_1', 'pca_2'])\n",
    "pca_df['label'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d09a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "\n",
    "target = [1,2,3,4,5,6]\n",
    "class_name = [\"WALKING\",\"WALKING_UPSTAIRS\", \"WALKING_DOWNSTAIRS\", \"SITTING\", \"STANDING\", \"LAYING\"]\n",
    "colors=['yellow', 'black', 'cyan', 'green', 'blue', 'red']\n",
    "\n",
    "for targets, color in zip(target,colors):\n",
    "    indicesToKeep = pca_df['label'] == targets\n",
    "    ax.scatter(pca_df.loc[indicesToKeep, 'pca_1']\n",
    "               , pca_df.loc[indicesToKeep, 'pca_2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "#print((indicesToKeep))\n",
    "ax.legend(class_name)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3134ac3f",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20806473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0ece44",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "X_train_tsne = tsne.fit_transform(X_train)\n",
    "X_train_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da996d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train_tsne[:, 0], X_train_tsne[:, 1], c=y_train, cmap=plt.cm.prism, edgecolor='k', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17fe498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_mds = mds.transform(X_test) # no transform\n",
    "\n",
    "clf = DecisionTreeClassifier(min_samples_leaf=3, random_state=42)\n",
    "clf.fit(X_train_tsne, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_train_tsne)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_train, y_pred))\n",
    "print('F1-score %s' % f1_score(y_train, y_pred, average=None))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fba279",
   "metadata": {},
   "source": [
    "### Plot al variare di Perplexity e N_Iteraz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c23e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform t-sne with different preplexities and their plots\n",
    "def perform_tsne(X_data, y_data, perplexities, n_iter=300, img_name_prefix='t-sne'):\n",
    "        \n",
    "    for index,perplexity in enumerate(perplexities):\n",
    "        # perform t-sne\n",
    "        print('\\nperforming tsne with perplexity {} and with {} iterations at max'.format(perplexity, n_iter))\n",
    "        X_reduced = TSNE(perplexity=perplexity).fit_transform(X_data) #verbose=2\n",
    "        print('Done..')\n",
    "        \n",
    "       # prepare the data for seaborn         \n",
    "        print('Creating plot for this t-sne visualization..')\n",
    "        df = pd.DataFrame({'x':X_reduced[:,0], 'y':X_reduced[:,1], 'label':y_data }) #,'label':y_data\n",
    "       \n",
    "       ## draw the plot in appropriate place in the grid\n",
    "        sns.lmplot(data=df, x='x', y='y', hue='label',  fit_reg=False, height=7,\\\n",
    "                  palette=\"Set1\") #markers=['^','v','s','o', '1','2']\n",
    "        plt.title(\"t-Sne with perplexity : {} and max_iter : {}\".format(perplexity, n_iter))\n",
    "        img_name = img_name_prefix + '_perp_{}_iter_{}.png'.format(perplexity, n_iter)\n",
    "        print('saving this plot as image in present working directory...')\n",
    "        plt.savefig(img_name)\n",
    "        plt.show()\n",
    "        print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d5e408",
   "metadata": {},
   "outputs": [],
   "source": [
    "classe = { 1 : \"WALKING\" , 2 : \"WALKING_UPSTAIRS\", 3 : \"WALKING_DOWNSTAIRS\", 4 : \"SITTING\", 5 : \"STANDING\", 6 : \"LAYING\"}\n",
    "y_train_activity = y_train[0].map(classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29586b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_tsne(X_data = X_train ,y_data=y_train_activity, perplexities =[20,50,100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
